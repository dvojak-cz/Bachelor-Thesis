\chapter{Definice problému a možná řešení}

\begin{chapterabstract}
Tato kapitola je zaměřena na hledání problému popsaného v úvodní části. Cílem této kapitoly je představit možné způsoby řešení problému a poukázat na výhody respektive nevýhody daného řešení.

Pro porozumění této kapitoly je dobré být seznámen se základním fungování orchestrátoru Kubernetes a principy síťování, které tento orchestrátor nabízí.  
\end{chapterabstract}
%Předchozí dvě sekce se zabývali pouze komunikací uvnitř klastru, která umožňuje komunikaci pouze mezi objekty Kubernetes. V případě potřeby komunikace mimo síť klastru Kubernetes poskytuje 3 řešení. port, loadbalancer, ven z kontejneru. Prvním způsobem je prostá komunikace z 


\section{Definice problém}
V úvodu a zadání této práce je nastíněný problém komunikace mezi vnitřní sítí klastru a privátními sítěmi, které přiléhají alespoň k jednoho z uzlů klastru. 

V rámci této kapitoly bude síťová komunikace označkovat komunikaci probíhající na síťové vrstvě referenčního ISO/OSI modelu -- konkrétně pomocí protokolu IP. Pro účely této práce se omezíme na protokoly TCP, UDP a HTTP.

Kubernetes poskytuje řešení pro několik typů síťové komunikace. Nejzákladnějším z nich je komunikace mezi Pody, které jsou součástí jednoho cloudu. Pro tento druh datového přenosu nepřináší Kubernetes žádnou formu omezení. Přenos je umožněn plně a všemi směry. 

Komunikace směrem do klastru z okolní sítě také není nijak zvláštně omezena. Pro tuto komunikaci lze využít některé ze standardních objektů, které Kubernetes nabízí (Ingress, Service). Tento druh přenosu vyžaduje konfiguraci, ale je umožněn bez jakéhokoliv omezení.

Posledním druhem komunikace je spojení klastru s okolní sítí, ve směru komunikace do okolní sítě. Toto spojení je bezproblémové v případě, že aplikace v klastru adresuje objekty, které jsou veřejně dostupné\footnote{Veřejně dostupným objektem budeme chápat libovolný server, který je dostupný ve veřejné síti internetu, a je dostupný ze všech výpočetních uzlů klastru} v okolní síti. Příkladem takového spojení je požadavek na veřejnou DNS službu. V případě, že některá z aplikací běžících v Kubernetes se obrátí například na server \verb|8.8.8.8|, pak komunikace proběhne bez potíží. Požadavek je na jednom z uzlů klastru pozměněn tak, aby byl validním v okolní síti mimo klastr (typicky je pozměněna hlavička IP protokolu - pomocí SNAT) a poté je požadavek vyslán do okolní sítě.

Problém nastává, pokud je vyžadována komunikace s okolní \textit{privátní} sítí. Privátní sítí myslíme síťový segment, který není dostupný ve veřejném internetu a zároveň není dostupný ze všech uzlů klastru. Tato situace je ilustrována na schématu \ref{fig:schema} níže.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.95\textwidth]{images/sampleNet.pdf}
    \caption{Ukázka síťového zapojení klastru}
    \label{fig:schema}
\end{figure}

Ve schématu jsou uvedeny celkem tři síťové segmenty. Síť \textit{internal\_kubernete} reprezentuje interní síť klastru.  Rozsah této podsítě \verb|10.244.x.x/16| je definovaný proměnnou \verb|PodCIDR|. Klastr se skládá z čtveřice výpočetních uzlů \textit{kmaster}, \textit{kworker}, \textit{kedge01}, \textit{kedge02}. 

Sítě \textit{private\_network01} a \textit{private\_network02} označují přilehlé privátní síťové segmenty. Omezme se na \textit{private\_network01}. Segment \textit{private\_network01} má přidělen rozsah IP adres \verb|172.17.16.x/24| a obsahuje dvě koncová zařízení (\textit{device01-01}, \textit{device01-02}). Síťový segment je zcela izolovaný s výjimkou napojení na zařízení \textit{kedge01}.

V uvedeném příkladu je privátní síť a interní síť spojena pouze jedním z uzlů klastru \textit{kedge01}. Tento uzel je do privátní sítě \textit{internal\_kubernetes01} a interní Kubernetes sítě \textit{internal\_kubernete} připojen pomocí dvou různých síťových karet. V obecném případě může více uzlů být připojeno do více privátních sítí a zároveň jedna privátní síť může být propojena s klastrem pomocí více uzlů. Uzly, které takto propojují privátní síť a vnitřní síť Kubernetes budou označovány jako \textit{edge uzly}.

\bigskip

V případě takového nastavení není přímo komunikace objektů klastru se zařízeními v privátních sítích umožněna (ve směru z klastru k zařízením).

Následující část práce bude zaměřena na hledání způsobu, jakým zmíněnou komunikaci umožnit tak, aby co nejvíce vyhovovala stanoveným požadavkům.

\subsection{Požadavky na řešení problému}\label{sec:pozadavky}
Pro účel práce má smysl stanovit požadavky na hledané řešení. Požadavky jsou následující:
\begin{itemize}
    %\item Oboustrannost komunikace\\
    %Komunikace by měla umožňovat oba směry -- z klastru do privátní sítě a z privátní sítě do klastru. I přesto, že jeden ze směrů je umožněn přímo návrhem %Kubernetes, tak konfigurace této komunikace není jednoduchá. Proto bude vyžadováno, aby řešení poskytovalo jednoduchý způsob pro komunikaci směrem do klastru.
    \item Obecnost řešení\\
    Řešení by mělo pokrýt všechny možné, výše zmíněné, situace -- mělo by umožňovat propojení s více privátními sítěmi za použití více než jednoho uzlu.
    \item Podpora TCP, UDP\\
    Řešení by mělo plně podporovat komunikaci pomocí síťových protokolů TCP a UDP a protokolů z vyšších abstrakčních kategorií.
    \item Jednoduchost\\
    Řešení by mělo být jednoduché z pohledu uživatele případně administrátora klastru. Jeho používání by nemělo být nijak zvlášť náročné s porovnáním používání jiných služeb Kubernetes. To samé platí pro jeho zavedení a případnou integraci do již existujícího Kubernetes klastru. Používání by mělo podporovat zavedené způsoby komunikace se systémem Kubernetes.
    \item Bezpečnost řešení\\
    Řešení by mělo být bezpečné a nijak významně by nemělo snižovat bezpečnost systému při použití.
\end{itemize}

\bigskip


Zmíněné komunikace lze dosáhnout dvěma způsoby, každý ze způsobů má jisté výhody a nevýhody. Jako první zde bude uveden způsob za použití existující technologie \textit{Kube~edge}, která by daný problém mohla do jisté míry řešit.
\section{Řešení pomocí Kube edge}
\href{https://kubeedge.io/}{Kube edge} je projekt společnosti cloud native computing foundation, který rozšiřuje Kubernetes pro použití na koncových zařízení (edge devices). Tento projekt je vyvíjen primárně pro potřeby \textit{edge cloud computing architektur} systému. \cite{bigelow_2021_what} Cílem projektu Kube~edge je usnadnit provoz Kubenets na zařízeních, která mohou mít omezené prostředky, jejich připojení není stále, stabilní a jsou provozovány na různých lokacích. Kube~edge umožňuje tyto zařízení integrovat do existujících Kubernetes klastrů. Díky tomut lze dobře pracovat s různými zařízeními, jako jsou například IoT zařízení, různé senzory, zařízení pro chytrá města atd. \cite{kubeedgeprojectauthors_2023_kubeedge}

Kube~edge je převážně určen k integraci zařízení, na kterých je možné provozovat samotné kontejnery a službu kubelet. Primární účel Kube~edge tedy neřeší výše popsaný problém, ale je velmi úzce spjatý s komunikací určitých zařízení a interní sítě Kubernetes. Z tohoto důvodu lze v implementaci Kube~edge nalézt alespoň částečné řešení zmíněného problému a to pro komunikaci za pomocí MQTT protokolu, případně protokolu HTTP.

\bigskip

Kube~edge obsahuje celkem šest komponent tvořících projekt. Jednou z těchto komponent je EventBus. EventBus je komponenta, která umožňuje komunikaci s externími zařízeními pomocí MQTT protokolu. Pokud by byl problém omezen pouze na komunikaci protokol MQTT, pak by EventBus řešil definovaný způsob komunikace a zároveň by splňoval veškeré stanovené požadavky.

Pro potřeby komunikace pomocí protokolu HTTP obsahuje Kube edge komponentu ServiceBus. Tato komponenta umožňuje komunikovat se službami běžícími na výpočetních uzlech koncových zařízení (jsou součástí klastru). Jedná se o komunikaci se službami, které nejsou přímo součástí systému Kubernetes. V uvedeném příkladu to znamená, že Kube~edge by umožnilo komunikovat se službou běžící na uzlech \textit{kedge01} respektive \textit{kedge02}. Tuto komunikaci lze představit jako loopback v rámci jednoho uzlu.

Komponenty ServiceBus lze rozšířit dvěma způsoby. Prvním způsobem je úprava zdrojového kódu Kube~edge tak, aby podporoval komunikaci i mimo klastr (výpočetní uzly). To by znamenalo, že \textit{edge uzly} by vytvořil most mezi privátní sítí a interní sítí Kubernetes. Tento způsob by byl funkční, ale velmi nestandardní a těžce udržitelný, proto není vhodným řešením. Druhý způsob je vytvoření HTTP služby, která by běžela na \textit{edge uzlech} a sloužila by jako prostředník komunikace. Tato služba by naslouchala na lokální adrese serveru a HTTP požadavky delegovala na daná koncová zařízení v privátní síti. Takové řešení by bylo funkční, ale velmi náročné na provoz. Zároveň by omezovalo problém pouze na HTTP protokol, což je v rozporu s požadavky na řešení. Pro stanovené požadavky je tento způsob také nedostačující. \cite{ttlv_2021_servicebusgo}

\bigskip

V obou zmíněných případech by Kube~edge poskytoval funkci prostředníka komunikace mezi sítí Kubernetes a privátní sítí.

Kube~edge je velmi zajímavá technologie, která je užitečná při integraci koncových zařízení do Kubernetes, ale pro účel propojení klastru s privátní je sítí nedostatečná. I přesto, že dnes Kube~edge nenabízí plné řešení problému, je dost pravděpodobné, že potřebná funkcionalita bude do projektu v budoucnu přidána. 

Cindy Xing (vedoucí projektu Kube~edge) a Kevin Wang (co-founder a vývojář Kube~edge) na konferencích KubeCon uvedli, že plánují rozšířit projekt tak, aby podporoval více protokolů. Zároveň zmínili, že se chtějí dále věnovat rozšíření stávající infrastruktury pro komunikaci a adresaci. \cite{cncfcloudnativecomputingfoundation_2019_intro}, \cite{cncfcloudnativecomputingfoundation_2022_intro}

\section{Řešení pomocí Proxy}\label{sec:req}
Popsané možné řešení za pomocí Kube edge by používalo tzv. prostředníka komunikace. V oblasti síťování se služba prostředníka nazývá Proxy. Proxy je služba, která umožňuje přistupovat k službám skrze tzv. proxy serveru (prostředníka). Často se používá pro přístup mezi více síťovými segmenty. Tato služba plní řadu funkcí. Mimo přeposílání komunikací může poskytovat zabezpečení, filtrovat tok dat, zaznamenávat informace o komunikaci apod. Proxy servery mohou pracovat na různých vrstvách ISO/OSI modelu, nejčastěji operují na vrstvě čtvrté respektive sedmé, kde operují s protokoly TCP, UDP respektive HTTP.

Proxy tímto nabízí velmi zajímavou funkcionalitu, která by mohla řešit zmíněný problém. Pokud, by bylo možné provozovat proxy na jednom z edge uzlů, pak by tato služba mohla sloužit jako most mezi privátní sítí a sítí Kubernetes. Taková služba by přeposílala komunikaci mezi interní sítí Kubernetes a přilehlou privátní sítí. K tomu, aby to bylo možné je zapotřebí, splnit následující požadavky:

\begin{itemize}
    \item Schopnost proxy serveru operovat na čtvrté a sedmé vrstvě ISO/OSI modelu
    \item Možnost spravovat jednotlivé proxy servery na edge~uzlech
    \item Proxy musí mít přístup k oběma síťovým segmentům (privátní síti a Kubernetes síti)
\end{itemize}

První požadavek je jednoduše splnitelný vhodným výběrem proxy serveru. Aplikací, které poskytují službu proxy a operují s protokoly TCP, UDP a HTTP je celá řada. Mezi nejznámější patří: Envoy, NGINX, SoCat, HAProxy atd. Každá ze zmíněných služeb je více či méně vhodná na určitý druh použití. Každá lze použít jako most mezi Kubernetes a privátní sítí.

Druhý požadavek se vztahuje ke správě jednotlivých proxy služeb. Je potřeba zajistit, aby proxy služba běžela na konkrétním edge uzlů, byl garantován její běh a aby bylo možné tuto službu jednoduše spravovat. K tomut lze využít stávájících služeb Kubernetes. Aplikaci proxy lze provozovat formou kontejnerů a naplánovat daný kontejner právě na potřebný \textit{edge uzel}.  

Posledním požadavkem je přístup k oběma síťovým segmentům. Provozovat proxy, v rámci systému Kubernetes, přináší řadu výhod, ale jednu zásadní nevýhodu. Aplikace provozované v systému Kubernetes mají přístup pouze do interního síťového segmentu. V každém podu se nachází právě jedno síťové rozhraní, které je napojeno do virtuální sítě Kubernetes. Toto je v rozporu s posledním uvedeným požadavkem. Z tohoto důvodu je potřeba umožnit kontrolu nad konfigurací síťových prostředků pro jednotlivé Pody tak, aby bylo možné kontrolovat dostupné síťové segmenty.

\medskip

V případě, že by bylo možné korektně provozovat proxy službu jako aplikaci v Kubernetes (všechny výše uvedené požadavky by byly splněny), pak by způsob za použití proxy serveru umožnil hledaný způsob komunikace a řešil by definovaný problém. Tento způsob by splňoval většinu z požadavků pro řešení, které jsou uvedeny v sekci \ref{sec:pozadavky}. Oboustrannost komunikace by byla splněna ze samotné podstaty fungování proxy. Pro oboustrannou komunikaci lze využít dvou služeb, kde každá z nich bude poskytovat komunikaci jedním směrem. Některé implementace umožňují oboustrannou komunikaci automaticky. Obecnost řešení je splněna díky vlastnostem Kubernetes. Služba lze jednoduše plánovat a spravovat na více uzlech zároveň. Podpora TCP a UDP je možná v případě, že se podaří správně nastavit síťové prostředky uvnitř Podu, ve kterém služba poběží. Bezpečnost a jednoduchost řešení je pak závislá na dané implementaci.

\medskip

V tuto chvíli je potřeba zajistit výše zmíněnou konfiguraci síťových prostředků pro Pod, ve kterém služba poběží. Pro pochopení jak tohoto dosáhnout, je dobré si připomenout, jak je nastavené síťování uvnitř Podu.

Ve zbytku této kapitoly budou diskutovány dva způsoby, kterými lze dosáhnout, aby Pod mohl komunikovat s více sítovými segmenty (obsahoval více než jedno síťové rozhraní).  

\subsection{Síťování uvnitř Podu}
Každý Pod sdílí síťový jmenný prostor mezi všemy kontejnery daného Podu. Tento síťový prostor je vytvořen běhovým prostředím kontejnerů na daném uzlu klastru. Běhové prostředí je ovládáno komponentou kubelet na daném výpočetním uzlu. Ve chvíli, kdy je jmenný prostor vytvořen, CNI pluginu vytvoří a vloží virtuální síťové rozhraní \verb|eth0| do daného prostoru. Zároveň nastaví komunikaci tak, aby splňovalo požadavky pro komunikaci mezi Pody definované systémem Kubernetes. Tímto způsobem vznikne nový síťový prostor pro Pod, ve kterém se budou nacházet rozhraní \verb|eth0| pro komunikaci s vnitřní sítí klastru a navíc rozhraní \verb|lo| (loopback). Ve výpisu \ref{cmd:podNet} níže je vidět popisované nastavení Podu.

\input{text/code/cmd_podNet}

\subsection{Root namespace}
Pro potřeby použití proxy uvnitř Kubernetes je nutné, aby Pod, ve kterém poběží služba proxy měl přístup k dvěma síťovým segmentům. K interní sítí Kubernetes a k privátní síti, do které bude proxy služba tvořit \uv{bránu}. To je potřeba, aby bylo možné přímo přistupovat k potřebným síťovým prostředkům uvnitř Podu a tak umožnit službě proxy korektně operovat na čtvrté vrstvě ISO/OSI modelu. Z toho důvodu je potřeba, aby Pod obsahoval alespoň dvě síťové rozhraní (pro interní Kubernetes síť a pro privátní síť se zařízeními). Ve výchozím nastavení Podu toto není možné, jelikož je vždy vytvořen nový namespace pouze s jedním rozhraním a tím je Pod uzavřen pouze do interní sítě Kubernetes a izolován o ostatních síťových segmentů.

Pro konfiguraci síťového jemného prostoru poskytuje Kubernetes API pouze jeden parametr \verb|pod.spec.hostNetwork|. Tento parametr je součástí definice Podu. Hodnota tohoto parametru nabývá pouze logické hodnoty \uv{True} nebo \uv{False}. Výchozí hodnota tohoto parametru je \uv{False}. Tímto parametrem lze specifikovat, zda Kubernetes má pro daný Pod vytvářet nový izolovaný síťový prostor, nebo využít stávající kořenový síťový prostor. V případě, že je tento parametr nastaven na hodnotu \uv{True}, pak všechny procesy uvnitř daného Podu mají přístup k síťovým prvkům v kořenovém jmenném prostoru (stejně jako běžící proces kubelet...). V takovém případě budou pro Pod dostupná všechna síťová rozhraní a navíc rozhraní \verb|eth0|, kterém bude připojeno do virtuální sítě Kubernetes. Ukázku tohoto si lze prohlédnout níže ve výpisu \ref{cmd:podHostNet}.

\input{text/code/cmd_podHostNet}

Tímto lze jednoduše splnit poslední podmínku pro provozování proxy, jako aplikace v Kubernetes. Nyní stačí správně spustit a nastavit proxy tak, aby propojovala síť privátní se sítí Kubenretes. Tato proxy by běžela v Podu s nastavenou hodnotou \verb|pod.spec.hostNetwork| na \uv{True}. Pod by běžel na potřebném edge uzlu.

I přesto, že je tento způsob zcela funkční, nesplňuje požadavek na bezpečnost, který je specifikován v sekci \ref{sec:pozadavky}. Řešení velmi narušuje virtualizaci, kterou nám kontejnery a Kubernetes poskytují. Tím je výrazně oslabena bezpečnost tohoto systému. Procesy běžící v Podu, by měly plný přístup k síťovým prostředkům hostujícího systému. To velmi rozšiřuje možnost útoku na hostující systém respektive na prostředí Kubernetes. Používání \verb|pod.spec.hostNetwork| lze označít za anti-pattern, právě kvůli narušení virtualizace. To potvrzuje i Mark Betz ve svém blogu \textit{Understanding Kubernetes networking}. 

\begin{displayquote}
\textit{\uv{In fact I would suggest that they are anti-patterns for 99.99 per cent of use cases, and any implementation that makes use of either should get an automatic design review.}} \cite{betz_2022_understanding}\\(Ve skutečnosti bych řekl, že jsou to anti-vzory pro 99,99 procent případů použití, a každá implementace, která je používá, by měla být přezkoumána.) 

\textit{\uv{I don’t think it’s a stretch to suggest that you are never, ever going to need to do this.}} \cite{betz_2022_understanding}\\(Nemyslím si, že by bylo přitažené za vlasy naznačovat, že tento způsob, nikdy nebudete potřebovat.) 
\end{displayquote}


Z výše zmíněných důvodů nelze toto označit za vyhovující řešení problému. Při použití by se mohlo stát, že by byl tento přístup zamítnut na základě stanovených bezpečnostních politik návrhářů systémů.

I přesto, že zmíněné řešení nelze označit za dostatečné, tak alespoň poskytuje možnost vyzkoušet, zda řešení pomocí proxy serveru je funkční a zda má smysl se jim dále zabývat. Pro účely implementace byla myšlenka testována a následně prezentována (pro účely HIL testování) právě za pomocí využití \verb|pod.spec.hostNetwork|. Pro test a prezentaci bylo nastavení služby proxy identické s nastavením, které je představeno v následující kapitole sekci \ref{ukazkaProxy}.

\subsection{Kubernetes a CNI}
Předchozí sekce ukazuje, jakým způsobem lze v Podu přistupovat k síťovým prostředků z kořenového jmenného prostoru. Zároveň zmiňuje, že způsob je funkční, ale nebezpečný kvůli zmíněnému oslabení virtualizace. Pro uspokojení požadavku na bezpečnost je potřeba umožnit Podu interagovat s více sítovými rozhraními, bez narušení virtualizace. V případě, že by bylo možné vytvářet Pody s více než jedním síťovým rozhraním a zároveň jednoduše konfigurovat síťové prostředky uvnitř izolovaného jmenného prostoru Podu, pak by bylo možné využít stejné řešení, jako při využití \verb|pod.spec.hostNetwork| a zachovat bezpečnost systému. Zbytku této kapitoly se budeme zabývat tím, jak tohoto dosáhnout. Pro účely porozumění řešení je potřeba si připomenout a ukázat, jak Kubernetes využívá CNI.

Již v teoretické části je , že Kubernetes k síťování používá CNI standardu. Container Network Interface specifikuje formát souboru, kterým lze definovat a konfigurovat jak mají být CNI moduly používány. Jedná se o informace ve formě JSON souboru, který je uložen na discích serverů klastru (pracovních uzlu). Tento soubor se nachází v adresáři \verb|/etc/cni/net.d/| na každém severu, který je součástí klastru. Kubernetes vždy pracuje se souborem, který se nachází v příslušném adresáři a je první dle abecedního pořadí. Tento soubor nese informace o verzi CNI a jménu CNI modulu, který má být využíván. CNI moduly jsou ve výchozím nastavení ukládány do \verb|/opt/cni/bin|. V případě, že systém využívá například modulu \textit{Flannel}, pak konfigurace CNI, uložená na jednotlivých serverech, bude konfigurovat daný modul a odkazovat na něj. Spustitelný modul implementující CNI (\textit{Flannel}) bude uložen v adresáři \verb|/opt/cni/bin|.

V dřívějších verzích Kubernetes bylo možné definovat cestu k adresáři s konfigurací pomocí \verb|--cni-conf-dir|, tento parametr byl ve verzi \verb|1.24| odstraněn. \cite{k8scirobot_2020_merge}, \cite{thekubernetesauthors_2022_networkPlugins} Cestu k CNI modulům je možné natavit pomocí proměnné prostředí \verb|CNI_PATH| na daném uzlu.

\subsection{Kubernetes Network Custom Resource Definition De-facto Standard}\label{sec:kncrdds}
Potřeba lépe kontrolovat síťové prostředky uvnitř Podu a přímo možnost vytvářet Pody s více síťovými rozhraními byla diskutovaná na konferenci \textit{KubeCon + CloudNativeCon North America} v roce 2017 v Austinu. \cite{woods_2018_a} Na této konferenci vznikla skupina \textit{NPWG} (Network Plumbing Working Group). NPWG vznikla primárně za účelem umožnit vytváření Podů s více síťovými rozhraními. Cílem skupiny bylo vytvořit specifikaci pro konfiguraci přídavných síťových rozhraní a následně implementovat jednoduché řešení pro účely prezentace jejich výsledků.

Zmíněná specifikace, která byla vytvořena skupinou NPWG se nazývá \href{https://github.com/k8snetworkplumbingwg/multi-net-spec}{\textit{Kubernetes Network Custom Resource Definition De-facto Standard}}. Tento standard slouží pro definici objektů a pro definici API, umožňující rozšíření standardního chování Kubernetes, o možnost vytváření Podů s více sítovými rozhraními. Specifikace definuje následující:

\begin{itemize}
    \item Objekt Network Attachment Definition\\
    Objekt NAD (Network Attachment Definition) je nový objekt, který specifikace přidává do Kubernetes API. Tento objekt je definován v doméně \verb|k8s.cni.cncf.io|. NAD slouží pro definici přídavných síťových rozhraní. Tento objekt obsahuje jediný parametr\\\verb|NetworkAttachmentDefinition.spec.conf|. V tomto parametru lze ukládat informace o přídavném rozhraní. Pro definici přídavného rozhraní stačí do zmíněného parametru uložit CNI konfigurační soubor, formou JSON.\\
    NAD umožňuje ukládat nastavení pro přídavná síťová rozhraní. Při vytváření Podu s přídavnými rozhraními jsou NAD objekty referencovány.
    \item Požadavky pro delegující CNI modul\\
    Network Custom Resource Definition specifikace definuje i základní požadavky pro implementaci tzv. delegující CNI moduly. Delegující CNI moduly označují moduly, které splňují tuto specifikaci. Pro účely práce nejsou tyto požadavky klíčové.\\
    Implementace a kompatibilita delegujících modulů je umožněna díky sekci standardu CNI o delegování práce modulů. Tato sekce je zmíněna v první kapitole \ref{cni}, odrážce \ref{enumerate:cni}.   
    \item Komunikaci pluginu s existujícími objekty Kubenretes\\
    Poslední důležitou částí, která je definovaná zmíněným standardem, je způsob integrace se stávajícími objekty Kubernetes. Zde je definováno, jakým způsobem definovat přídavné rozhraní v definici Podu. K tomut jsou využívaný anotace v metadatech Podu. Anotace označuje objekt, který je součástí metadat Podu a umožňuje uchovávat libovolné textové hodnoty ve formě páru (klíč, hodnota).\\
    Specifikace využívá anotací právě pro komunikaci s delegující CNI moduly a pro nastavovaní přídavných rozhraní. V případě potřeby nastavení přídavného rozhraní, stačí na daném Podu vytvořit anotaci s klíčem \verb|k8s.v1.cni.cnf.io/network| a hodnotou, která odpovídá názvu dříve vytvořeného NAD objektu.\\
    Specifikace udává i další způsoby, jakým lze definovat přídavné rozhraní přímo v definici Podu. Zároveň udává další pravidla pro komunikaci s delegující CNI moduly. Tyto způsoby a pravidla jsou specifická pro různé případy použití a proto zde nebudou uvedeny. V případě zájmu je možné tyto informace najít v samotné specifikaci. 
\end{itemize}
Díky této specifikaci a delegujícím CNI modulům, které specifikaci implementují, je možné vytvářet Pody s více síťovými rozhraními. Network Custom Resource Definition tak řeší poslední požadavek pro možnost použití proxy (definovaný v sekci \ref{sec:req}). TímWto je možné využít proxy pro řešení problému propojení interní sítě Kubernetes a přilehlé privátní sítě.

\bigskip

Navrhované řešení, kombinující použití proxy serveru a \textit{Kubernetes Network Custom Resource Definition (CRD) de-facto standardu}, je efektivní a praktický přístup k umožnění komunikace mezi interní sítí Kubernetes a přilehlou privátní sítí. Navrhované řešení nabízí potřebnou flexibilitu, bezpečnost a škálovatelnost.

