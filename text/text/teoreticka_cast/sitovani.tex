\section{Standartní síťování v kubernetes}
Síťování je velmi důležitou částí kubernetes. Kubernetes poskytuje celkem 4 řešení pro síťování uvnitř clusteru. V následující části se zaměříme primárně na komunikaci, které probíhají na transportní vrstvě, nebo vyšší - dle standartu ISO/OSI. Předpokládejme, že pro síťovou vrstvu používáme protokol \term{IP} verze 4 (\term{IPv4}).

\subsection{Kontejner s kontejnerem uvnitř podu}
Díky tomu, že jednotlivé kontejnery z jednoho podu sdílí stejný síťový jmenný prostor mají všechny kontejnery přístup ke stejným síťovým systémovým prostředkům. Všechny kontejnery v podu mají sdílené síťové zařízení, stejnou IP adresu a další prostředky. Zároveň každý pod obsahuje síťové rozhraní typu \term{loopback}. Komunikaci mezi kontejnery je tedy prováděna pomocí \term{loopback} rozhraní. To v praxi znamená, že kontnery v podu mohou posílat data na rozhraní loopback a ostatní kontejnry mohou na loopback adrese naslouchat.\footnote{V případě potřeby mohou kontejnery komunikovat pomocí System V IPC objektů}

\subsection{Komunikace Pod s Podem}
Při komunikaci podu s podem nastává problém, jelikož si nevystačíme pouze s vlastnostmi OCI kontejnerů. Při komunikaci Podu s jiným podem je často zapotřebí zprostředkovat komunikaci mezi více než jedním uzlem klastru.
Tento typ komunikace musí vyřešit problémy jako přidělování IP adres Podum, sdílení dat mezi více uzly, kontrola kolizí portu, routování mezi uzly\ldots

Řešení zmíněných problémů je netriviální a velmi těžko obecně implementovatelné tak, aby vyhovovalo každému nasazení kubernetes. Z tohoto důvodu není řešení této komunikace součástí kubernetes. Namísto toho se kubernetes odvolává na zmíněný standard CNI. Proto aby kubernetes podporoval zmíněnou komunikaci musí být po instalaci a inicializaci k8s nahrán modul (CNI plugin), který požadovanou komunikaci dokáže zprostředkovat\ldots{Tyto pluginy lze jednoduše inicializovat jako objekty kubernetes (nejčastěji pody, deploymenty a deamondsety).}.

První požadavek na funkční CNI modul pro potřeby kubernetes je zajištní nastavení síťových rozhraní v podu. I přesto, že CNI pracuje převážně s kontejnery, je možné CNI pro účely konfigurace podu použít. Stačí nastavit rozhraní jednomu z kontejnerů v podu a díky sdílení jmenného prostoru nastavení projeví v celém podu. Tento požadavek je jednoduché splnit, za použití referenčních modulů CNI, které autoři CNI a CNI komunita vytvořila.\footnote{Tyto moduly lze nalézt na \href{https://github.com/containernetworking/plugins}{https://github.com/containernetworking/plugins}}

Druhým požadavkem, který je kladen vývojáři kubernetes na vývojáře CNI modlů je umožnit přímou komunikaci mezi Pody skrz více uzlů. Tento požadavek je netriviální problém a není nijak více specifikovaný. Absence této specifikace klade na CNI moduly vysoké nároky, jelikož by v ideálním případě měli pracovat s libvolnou infrastrukturou(prostředky OS na uzlu, infrastruktura sítě, politika sítě....). Většina řešení tohoto problému se dá rozdělit do 4 základnách skupin (full mesh of static routes, Orchestrating the underlay, Encapsulating in the overlay, Cloud API).\cite{kashin_2022_cni}\cite{callendrello_2019_kubernetes}. V případě, že se všechny uzly nachází na stejné L2 ISO/OSI vrstvě, je možné routování dosáhnout pomocí statické konfigurace routovacích pravidel. Druhým způsobem je využití směrovacích protokolů (například BGP), případně dynamickým nastavováním routovacích pravidel. Tento způsob umožňuje práci s uzly mezi odlišnými L2. Tento způsob se nazývá Orchestrating the underlay (calico). Velmi často využívaným způsobem je využití VXLAN, díky které lze enkapsulovat network (flannel). Posledním způsobem jsou často proprietární řešení, která umí komunikovat přímo s prvky zajištující síťování. Tento způsob je typický pro cloud providers (cp-azure) Cloud API.

Pro správné fungování nutné i správně přidělovat IP adresy jednotlivým Podům. Toto je také součástí implementace CNI. V drtivé většině jsou Podům přidělován adresy z rozsah, který náleží danému serveru. Tento rozsah lze vyčíst z proměnné \term{podCIDR}, která se nachází ve specifikaci každého uzlu klastru. Tento rozsah je odvozen z proměnné \term{clusterCIDR}. Tato proměnná uchovává rozsah pro libovolný pod v celém klastru. \textit{podCIDR} jsou tedy jednotlivé podsítě \textit{clusterCIDR}. Užití těchto rozsahů definovaných v proměnných je pouze doporučený postup pro implementaci CNI, nejedná se o nutné pravidlo.\cite{callendrello_2019_kubernetes}       

Díky tomu, že kubernetes deleguje tento druh síťování na CNI pluginy, které mají relativně velkou volnost implementace, je možné síťování přizpůsobit pří na míru použití clusteru kubernetesu.

Pro přiblížení zmíněných informací může posloužit ukázka nastavení klastru. Tento klastr se skládá celkem ze tří serverů, které jsou pojmenované \textit{kmaster}, \textit{kworker1} a \textit{kedge1}.
\cite{vasilatos_2019_kubectl}
%\begin{figure}[!htbp]
\begin{verbatim}
# get list of nodes and their podCIDR range
[_]$ kubectl get nodes -o json \ 
| jq '[.items[]|{node:.metadata.name,podCIDR:.spec.podCIDR}]' \
| yq -P
>>> - node: kedge1
>>>   podCIDR: 10.244.2.0/24
>>> - node: kmaster
>>>   podCIDR: 10.244.0.0/24
>>> - node: kworker1
>>>   podCIDR: 10.244.1.0/24

# get global cluster-cidr for cluster
[_]$ kubectl cluster-info dump | grep -m 1 -oE 'cluster-cidr=[^"]+'
>>> cluster-cidr=10.244.0.0/16

# get list of pods and theyr internal IP addresses coresponding to node podCIDR  
[_]$ kubectl get pods -o json \
| jq '[.items[]|
  {name:.metadata.name,ip:.status.hostIP,node:.spec.nodeName}]' \
| yq -P
>>> - name: debug-edge-7b9bff85d4-j9t26
>>>   ip: 172.16.16.111
>>>   node: kedge1
>>> - name: http-server-67b6fc474b-dhzll
>>>   ip: 172.16.16.101
>>>   node: kworker1
>>> - name: kube-controller-manager-kmaster
>>>   ip: 172.16.16.100
>>>   node: kmaster

\end{verbatim}
%\end{figure}



\cite{a2022_cluster} 
Doporučené CNI lze nalézt na stránce kuberenets (\href{https://kubernetes.io/docs/concepts/cluster-administration/addons/#networking-and-network-policy}{kubernetes.io}).

\subsection{Komunikace pomocí Service}
Výše popsaná komunikace je zcela funkční, ale značně limitovaná. Přímá komunikace mezi pody je závislá na konfiguraci jednotlivých podů. Konkrétně na jejich IP adresách, které jsou podům přiděleny. V případě, že jeden z podů chce komunikovat s podem jiným musí znát jeho IP adresu a na tu požadavky adresovat. Bohužel na stálost a neměnnost IP adress u podů není spoleh. Z tohoto důvodu je potřeba umožnit jednotlivým aplikacím dynamicky objevovat IP adresy služeb, které chce daná aplikace adresovat. Této funkcionalitě se v anglickém jazyce říká \textit{service discovry}, do českého jazyka by se dalo přeložit jako \textit{objevování služeb}. 

\textit{Service discovry} je proces dynamického, objevování IP adres, případně routovacích pravidel, v síti. Jednou z nejznámější služeb poskytující \textit{Service discovry} je \textit{DNS}. Pro dynamické objevování služeb v zásadě existují dvě řešení. Aplikace (často označované jako klientské) mohou \textit{service discovry} provozovat sami. Druhou možností je delegovat problém na jiné služby, jako právě \textit{DNS}, \textit{load balancery} \ldots Zaměřme se nyní na tyto dva způsoby v systému kubernetes. 

Zmíněné první řešení v kubernetes by znamenalo, implementovat do jednotlivých aplikací službu, která by komunikovala přímo s \textit{kube-api}. Takto by bylo možné, aby si aplikace sami zjišťovali potřebné informace o okolních službách v klastru, které by následně mohli adresovat. Tento způsob má určité výhody, ale několik zásadních nevýhod. Mezi ty nejzásadnější nevýhody patří: související bezpečnostní problémy a s nimi spjatá správa klastru, zvýšené nároky kladené na vývojáře aplikací. Zároveň tento způsob jde proti GRASP\footnote{Grasp označuje General Responsibility Assignment Software Patterns (Obecný přiřazovaní zodpovědností - Software pattern) je návrhový vzor, který prosazuje nízkou provázanost a vysokou soudržnost.}\cite{bisi1} návrhovému vzoru. Zároveň není použitelný pro aplikace, které nejsou přímo připraveny pro běh v prostředí kubernetes (takové aplikace se označují \textit{kube-ready}). Tento způsob řešení service-discovery není obecně preferovaný, právě z důvodů zmíněných nevýhod.

Druhý způsob nabízí možnost delegace problému na jinou službu poskytující objevovaní služeb. Vzhledem k tomu, že problém \textit{Service discovry} je již dobře známí a zdokumentovaný, má již téměř standardní řešení. Většinou se pro tento problém  používá \textit{reverse proxy} respektive \textit{loadbalancing}. Zmíněné služby abstrahují přímé připojení k dostupným aplikacím. Ve většině případů se postaví mezi klientskou aplikaci a nabízenou službu. Následně samy vystavují body pro připojení a zprostředkovávají doručení komunikace koncovým službám. V praxi to znamená, že klienti, se přímo nepřipojují na danou službu, ale na reverse proxy (případně jinou službu), která požadavky přepošle na koncovou aplikaci. Proto, aby toto řešení fungovalo, musí být adresa reverse proxy známá a neměnná, reverse proxy musí být spolehlivá a dostupná v nejvyžší možné míře. Zároven musí zajistit správné přeposílání požadavků klientů na poskytované služby, což v důsledku znamená, že musí znát koncové aplikace.

Variací reverse proxy ve světě kubernetes je právě objekt \textit{Service}. Oficiální dokumentace kubernetes uvádí, že \enquote{\textit{Service je metoda vystavování síťových aplikací, které běží v jednom, nebo více podech.}}\cite{a2023_service}. Toto přesně splňuje úkon, který poskytuje i výše popsaná reverse proxy. Služba Service má následující vlastnosti: je adresovatelná v celém klastru pomocí IP adresy i DNS jména, zprostředkovává komunikaci s jedním, nebo více pody v klastru, je spolehlivá a perzistentní (její IP adresa je neměnná). Toto jsou přesně vlastnosti, které jsou potřeba pro výše popsaný problém.

Pro jednoduché pochopení fungování servise je dobré se seznámit s definicí service, které poskytuje \textit{kube-api}. Ukázku této definice lze vydět níže \ref{fig:def_service}.
\begin{figure}[!htbp]
\caption{Ukázka reprezentace objektu SERVICE}
\label{fig:def_service}
\begin{verbatim}
kind: Service
apiVersion: v1
metadata:
  name:  service-name
spec:
  selector:
    app: pods-label # label of pod to identify 
  type: ClusterIP   # type of service (LoadBalancer | ClusterIP | NodePort)
  ports:
  - port:  80               # exposed port by servise
    targetPort:  8080       # port on pod
\end{verbatim}
\end{figure}

Prvním důležitým parametrem je název, každý objekt Service musí tento název obsahovat. Jméno následně slouží jako DNS klíč při adresování dané Service. O správný překlad adres se postará interní DNS server. Druhým velmi důležitým parametrem je \verb|selector|. Selector slouží k propojení dané Servise s pody, na které budou požadavky přeposílány. V příkladu \ref{fig:def_service} budou adresovaný všechny pody, které obsahují označení \verb|app: pods-label|. Posledním důležitým parametrem je pole portů, které určují jakým způsobem má být případná komunikace na jednotlivé pody přeposlána.

Díky tomuto je možné popsat způsob, kterým lze pomocí Service komunikovat s koncovými aplikaci běží v koncových podech. Jediné, co v definici chybí je IP adresa, dané Service. Tento parametr lze v definici vynutit pomocí \verb|clusterIP|. Pokud daná IP adresa není specifikovaná, pak kubernetes vybere IP adresu sám. Tato IP adresa je po dobu existence Service neměnná a zaznamenaná v interním DNS serveru.  

Zde je příkladem komunikace za pomocí servise. Mějme klientskou aplikace běžící v podu \verb|C|, která by chtěla komunikovat se službou běžící v podu \verb|A|. Zároveň v kuberenets existuje objekt Service \verb|S|, který přeposílá požadavky na zmíněný pod \verb|C|. Pod A chce vyslat požadavek na službu běžící, která je dostupná pomocí \verb|S|. Proto zašle požadavek přímo na \verb|C|, na daný port, který je přede dohodnutý. Toto je spolehlivé, jelikož \verb|C| má neměnnou IP adresu, jejíž hodnota je získatelná z interního DNS kubernetesu. V tuto chvíli opouští paket pod s cílovou adresou \verb|S|. Ještě než paket zcela opustí daný node, je díky kubernetes pozměněna cílová adresa tak, aby směřovala přímo na daný pod \verb|A|, kde běží potřebná služba. Při cestě paketu opačným směrem je adresa opět pozměněna, aby pod \verb|C| nepoznal, že k nějaké změně vůbec došlo. Za povšimnutí stojí, že klientský pod \verb|C| nemusí nic o existenci podu \verb|A| vědět, celá komunikace je abstrahována prostřednictvím service. Problematika Service je velmi složitá, proto zde vudedu základní otázky na odpovědi, které by člověka mohli přirozeně napadnout, pro větší pochopení Service doporučuji nastudovat oficiální dokumentaci kubenretes a web \href{https://www.tkng.io/}{The Kubernetes Networking Guide}. Překlad adres na jednotlyvých nodech zajišťje komponenta \textit{kube-proxy}, často pomocí \textit{IPtables}. Implentace překladu adres se může měnit dle použitého CNI. Objekt service není přímo adresovatelný pomocí IP adresy. Adresovatelnost zajišťuje objekt \term{Endpoint}, respektivě objekt \term{EndpointSlice}, tento objekt je úzce spojen s objektem Service. Rozsah defaultně přidělovaných IP adres pro Services je uchován v  proměnné \verb|service_cluster_ip_range|, defaultně se jedná o rozsah \verb|10.43.0.0/16|\cite{a2023_rancher}



\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.60\textwidth]{images/service1.png}
    \caption{Caption1}
    \label{fig:service1}
\end{figure}
\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.60\textwidth]{images/service2.png}
    \caption{Caption2}
    \label{fig:service2}
\end{figure}

Takto popsané použití Service je pouze jedním ze tří základních módů Service. Těmito módy jsou \term{ClusterIP}, \term{NodePort}, \term{LoadBalancer}.\footnote{Headless mode je nyní záměrně vynechán, jelikož se nejedná o standardní mód. tento mód bude vysvětlen v kapitole ??} 

\subsubsection{ClusterIP}
Cluster IP je nejzákladnější způsob fungování Service. V tomto módu plní všechny výše popsané služby. Tento mód se používá převážně pro interní komunikaci podů v klastru. 
\subsubsection{NodePort}
Node port je variace předešlého ClusterIP módu. Kromě zmíněných funkcionalit zároveň vystavuje službu i mimo interní síť klastru. Daná služba (v tomoto módu) bude dostupná pod definovaným portem na všech IP adresách samotných nodes. Za tuto funkcionalita je také zodpovědná komponenta \textit{kube-proxy}. Při příchodu paketu na danou adresu nodu je adresa přeložena na adresu podu, stejně jak tomu je v případě komunikace po interní síti.   
\subsubsection{LoadBalancer}
LoadBalancer je dle Nigel Poulton\cite{poulton_2022_the} nejpoužívanějším módem Service. Tento mód je do jisté míry podobný variantě \textit{NodePort}. Také poskytuje veškeré funkcionalit z \textit{ClusterIP} a také umožňuje a adresovat interní service z externí sítě. Pro vystavení Service do okolní sítě vytváří unikátní IP adresu, která je adresovatelná z vnějšku sítě. Proto aby tato funkcionalita fungovala, musí být zajištěna funkcionalita LoadBalancingu. V případě použití poskytovatelů klaudových služeb je tato funkcionalita nabízena jako poskytovateli. V případě on-preimse řešení lze využít softwerových implementaci loadbalanceru jako například MetalLB. Pro robustnější řešení lze zajistit hardwarovou podporu Loadbalancingu. 


% Problém nastává ve chvíli, kdy je potřeba adresovat pod s neznáme IP adresu uvnitř klastru. Tento problém nastává často, například při použití objektu Deployment. Deployment zaručuje běh potřebných podů, ale nijak nedefinuje jaká IP adresa bude podům přidělena. Dokonce se v tomto případě může IP adresa po dobu existence Deploymentu měnit. Toto značně kompilkuje komunikaci mezi pody v klastru. Zmíněný problém se v anglické literatuře označuje jako \textit{service discovry}, do českého jazyka by se dalo přeložit jako \textit{objevování služeb}. \\ Druhým řešení je využití kubernetes objektu \textit{Service}. \\ Service je objekt kubernetesu, který pomáhá s síťování nejen uvnitř clusteru. Tento objekt abstrahuje komunikaci se službami, které jsou dostupné po síti. Službou budeme myslet libovolný koncový bod (endpoint), který reaguje na TCP, UDP požadavky.\footnote{pozor, neplést službu a objekt Service} Příkladem této služby může být \\ Komunikaci abstrahuje tím, že shlukuje skupinu podů a tyto pody vystavuje pod známou adresou. Často se Service přírovnává k \textit{load-balancer}, jelikož funguje velmi podobně. Díky této abstakci je možné komunikovat s Service, které IP adresa je dohledatelná v vnitřnm DNS. Objekt a služba Service pak zajití, že se komunikace dostane až na požadovaný pod, případně množinu podů. Díky tomuto mohou aplikace v kubernetes delegovat porblém \textit{service discovry} právě na službu Services. \\ Služba Service může pracovat ve čtyřech základních módech: \\ Objekt Service n8m umožuje adresovat pod, případně skupinu podů, pomocí stálé IP adresy, případně DNS jména. Service se za nás stará o adresování podů, které majíí ephemerla IP adresu. V případě nasazení aplikací jako typu deploiment se tedy nemusíme starat o potenciálně se měnící IP podu. \footnote{zdroj: https://kubernetes.io/docs/concepts/services-networking/service/, https://www.tkng.io/services/} \\ \footnote{https://deepkb.com/CO_000014/en/kb/IMPORT-1f5d92ef-6897-34d3-8f15-6bdf5ded890c/service}

\subsection{Ingress}
\textbf{Zavest konvenci jednosmerne komunikace (komunikace jako INPUT na FW)}

Jedním z velmi často využívaným objektem kubenretes z kategorie síťování je \term{ingress}. \term{Ingress} je relativně nový objekt v Kubernetes, do standardního API byl zařazen ke konci roku 2020\footnote{https://github.com/kubernetes/kubernetes/tree/v1.20.0}. Do této doby doby byl veden pouze jako \term{v1beta1}\cite{kashin_2021_gateway} a nebyl tak znám jako dnes.

Ingress je v oficiální dokumentaci uveden jako \textit{API objekt, který spravuje externí přístup k services vně klastru, typicky pomocí HTTP. Ingress může poskytovat služby loadbalancngu, SSL a routování na základě doménových jmen.} \cite{a2023_ingress} Jedná se tedy o objekt, který vystavuje přístup k objektům typu servcices uvnitř klastru. Ingress si proto lze představit jako vstupní bránu celého klastru, která umožujě dostupnost některých aplikací v klasru okolnímu světu. Velmi dobře je toto znázorněno na schématu níže \ref{fig:ingres}, která znázorňuje klienta, který přistupuje pomocí ingress a service až k jednotlivým podum. 

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.90\textwidth]{images/ingress.png}
    \caption{ingres}
    \label{fig:ingres}
\end{figure}

Mohlo by se zdát, že \textit{ingress} je duplicitním řešením pro již existující objekt \textit{Service} v reřimu \textit{NodePort} nebo \textit{LoadBalancer}. Je pravda, že podobné chování lze docílit pouze za použití service. Ingres ale navíc doplňuje a rozšiřuje některé funkce \textit{Serrvice} a zároveň řeší některé z problémů, které mohou při použití \textit{Service} nastat. Zároveň je ingres často preferovaným způsobem pro vystavování aplikací, před čistým použitím service a to z dvou hlavních důvodů.

Prvním důvodem je kontrola routování. V případě použití services pro účely vystavení služeb běžících v sítí kubernetes lze routování nastavit pouze na síťové respektive transportní vrstvě dle ISO/OSI modelu. Service v módu nodePort nám umožňují nastavovat routování pouze za pomocí portů a typu transportního protokolu (TCP a UDP). V případě service typu LoadBalancer zle routování kontrolovat navíc pomocí IP adres. Toto může být značně omezující, pro různé typy služeb (jako například loadbalacing\ldots) může dávat smysl kontrolovat routování pomocí protokolů výších vrstev. Právě možnost kontroly routování až za pomocí aplikační vrstvy ingres přináší.

Druhým důvodem, proč ingres hojně využívaný je fakt, že může velmi omezit finanční nároky na vystavování aplikací v komerčních klaudech, jako jsou Azure, AWs, Google... Velmi často se stává, že poskytovatele klaudových služeb si účtují poplatky za každou existující veřejnou IP adresu a zároveň za její konfiguraci. Tyto poplatky se pak mohou účtovat za každou LoadBalaner service. V případě použití objektu ingress se zodpovědnost za loadbalancing přenese dovnitř samotného klastru a zároveň pro fungování ingres bude potřeba pouze jedna veřejná IP adresa. Díky tomuto lze znatelně omezit výdaje, při použití veřejných poskytovatelů klaudů.

\subsubsection{Implementace ingress}
Důležité je zmínit, že ingress je pouze API, které kubernetes definuje. Jednotlivá implementace tohoto objektu se může lišit v závislosti na použitém kontroleru. V případě jednotlivých implementací se bavíme o implementaci samotného ingress kontroleru. V tomto případě se jedná o modul, který rozumí definovanému API, dle kterého plní potřebné funkce. Jednotlivé implementace kontrolerů se mohou výrazně lišit, dle dané infrastruktury, prostředí a potřeb použití. Zároveň je ingress API dosti volné a umožňuje rozšíření pomocí CRD (Custom Resource Deffinition)\footnote{CRD je objekt kubernetes, který umožňuje rozšiřovat API. Tento objekt bude ještě vysvětlen v kapitole /ref\{...\}}. Jak již bylo zmíněno, ingress dlouhou dobu nebyl součástí kuberenets. Toto vedlo k tomu, že vznikali řešení třetích stran \cite{kashin_2021_gateway}. Proto si myslím, že je ingress API navrženo velmi volným způsobem, aby co nejméně limitovalo již existující řešení.

Příkladem kontrolerů implementující funkci ingress, které jsou přímo podporovány kubernets  jsou: \footnote{AWS Load Balancer Controller}, \textit{Google-Cloud LoadBalancer controller}, \textit{Ingress NGINX Controller}. Komtrolery třetích stran pak implementují kontrolery pro Azure Cloud \ldots

\subsubsection{Routování pomocí aplikační vrstvy ingress}
Jak již bylo zmíněno, tak ingress umožňuje nastavovat routování dle nejvyšší vrstvy abstrakce ISO/OSI modelu, konkretně pomocí http protokolu. Pro účely pochopení routování se nyní zaměříme pouze na samotný protokol HTTP bez jakéhokoliv zabezpečeni jako \term{TLS}.

Pro definici routování ingres používá list pravidel (rules). Tyto pravidla pak konfigurují samotný ingress kontroler, prvky listu definují pravidla pro routování. Příklad pravidel lze vidět níže.
\begin{verbatim}
rules:
- host: foo.com
  http:
    paths:
    - path: /API
      pathType: Prefix
      backend:
        service:
          name: test
          port: 
            number: 80
\end{verbatim}
První způsob, kterým lze kontrolovat routování je DNS jméno, které je použito pro samotný přístup k servisám v klastru. DNS jméno lze specifikovat dle standardu RFC 3986 jako část URI označovaná \textit{host}. Momentálně ingress nepodporuje specifikování portu pomocí \term{:} oddělovače. Možnost specifikace pomocí portu je diskutována.\footnote{Je to pravda?}  Jediný podporovaný port je 80 respektive 443 pro https. Pomocí nastavení routování lze dobře oddělovat jednotlivé přístupy. Příkladem by mohly být odlišné service pro backend a frondendovou část aplikace, kdy obě services jsou dostupné ze stejné IP adresy ale pod jiným doménovým jménem \term{front-end.example.com} respektive \term{back-end.example.com}.

Druhý způsob routování, které je možné specifikovat pomocí ingress jsou cesty. V kontextu ingress cesta označuje část URI dle RFC 3986, která je označovaná jako "path". Díky tomuto lze oddělit například verze aplikací. Takové použití by mohlo vypadat tak, že \term{back-end.example.com/v1} bude odkazovat na verzi jedna aplikace a \term{back-end.example.com/v2} bude odkazovat na verzi 2. Při konfiguraci lze cesty lze specifikovat, zda danému pravidlu mají odpovídat všechny cesty s daným prefixem, nebo pouze cesty, které přesně odpovídají danému vzoru. Případně lze určit, že pravidlo pro cestu má být takzcaně implementačně specifické. V tomto případě je chování definované samotnou implementací kontrolleru. \cite{a2022_ingress}. Výše popsané způsoby routování lze kombinovat

Toto jsou způsoby definice routování, které ingress nabízí. Ve chvíli, kdy ingerss přijme požadavek, který uspokojí vydefinovaná pravidla, pak přeposílá požadavek dále do klastru a plní tak funkci reverse proxy. Ingress je určen k tomu, aby požadavky přeposílal na objekty service. Tyto požadavky jsou pak díky service doručeny na potřebné pody a aplikace běžící uvnitř. Reference na tyto service jsou součástí zmíněných pravidel pro routování. I přesto, že ingress je myšlen převážně pro poskytovaná proxy proxy pro service, je možné využít i pro libovolně jiné účely. I přesto, že toto použití je nestandardní, ingress API je pro tyto účely připraveno.   

\subsubsection{Šifrování pomocí ingress}
Doposud popsaná funkce routování je závislá na datech HTTP protokolu. V případě, komunikace není zabezpečena, pak jsou tyto data volně dostupná a ingress s nimi může pracovat. V případě, že by byla komunikace mezi klientem a aplikací v kubernets šifrovaná pomocí TLS, nemůže ingress parametru v HTTP datech vyříst (pokud nemá přístup ke klíčům, použitý pro šifrování). Z tohoto důvodu nabízí ingess i možnost zprostředkování TLS šifrování pro komunikaci mezi klienty a samotným ingress objektem. Delegace šifrování na samotný ingress má dvě zásadní výhody, oproti šifrování až na straně aplikace v klastru. 

První výhodou je, že ingress má přístup k datům. Jelikož komunikaci sám šifruje, pak může nahlížet i do dat komunikace a díky tomu poskytovat zmíněné routování dle parametrů HTTP protokolu.

Ingress poskytuje jedno jednoduché řešení pro zabezpečení veškeré komunikace, která je vedena přes objekt ingress. Toto je druhá výhoda tohoto řešení. Díky tomuto není zodpovědnost zabezpečení na vývojářích aplikace, ale na administrátorech daného klastru. Zároveň je logika šifrování implementované v ingress kontroleru, což je preferovanější, než aby se o bezpečnost starali vývojáři klaudových aplikací.\footnote{Citovat BI-BEK kokese}

\subsection{Engress}
Výše popsaný objekt ingress je určen pouze pro jednosměrnou komunikaci směrem do klastru. Při komunikaci směrem z klastru ven se často hovoří o takzvané engress funkcionalitě. Jak již název napovídá, engress označuje opačnou funkcionalitu a myšlenku oproti zmíněnému ingerss. I přesto, že termín engress je zmíněný v oficiální dokumentaci kubernetes, tak samotný kubernets tuto funkcionalitu neimplementije ani nedefinuje. Komunikace z klastru ven proto není nijak zdokumentovaná v kubernetes.

O komunikaci z podů klastru do veřejného internetu se primárně starají CNI pluginy. Defaultní nastavení většiny známých CNI pluginů, je provádět překlad adres přímo na uzlu klastru, kde daný běží pod, který se chce spojit s veřejnou sítí. Tento způsob dává dobrý smysl, jelikož nevyžaduje žádnou konfiguraci ani složiitou implementaci. Zároveň, díky plánování podu, nezatěžuje jednu část sítě, ale určitým způsobem balancuje síťovou zátěž mezi jednotlivé pody. Samozřejmě může nastat chvíle, kdy je potřeba vést komunikaci určitým směrem, například přes jeden z dostupných uzlů klastru. Pro tyto účely je možné použít pokročilé CNI plugins, které tuto funkcionalitu nabízejí (například coil)\cite{yamamoto_2020_introducing}. Dalším možným řešením je použití nástroje třetích stran pro správu service, jako je například consul. Je možné, že v budoucnu bude tento problém řešen standartně pomocí kubenretes, ale momentálně dokumentace uvádí, že to možné není.\cite{a2022_network}

%Ingres je navržen tak, aby sloužil jako obecný HTTP loadbalancer, který přeposílá požadavky jednotlivým apliakcím běžícím v klastru. Lze si ho představit jako vstupní bránu celého klastru, která umožujě dostupnost některých aplikací v klasru okolnímu světu. Objekt ingress je pouze definicí, nikoliv   



%Prvním problémem je objekt do  a slouží k řešení dvou hlavních problémů, které dosavadní řešení pomocí služeb (services) neřeší

%Posledním důležitým . Ingress je objekt, který propojuje interní síť klastru s okolním světem. Zároveň se jedná  objekt, který umožňuje komunikaci inicializovat pouze jedním směrem a to z okolní sítě do sítě interní \footnote{Jednosměrnou inicializací se myslí, jakým směrem je možné vyslat první paket spojení. Po \enquote{otevření} komunikačního kanálu je možné data posílat i směrem z klastru ven, ale první paket musí přicházet dměrem dovnitř. Jedná se o podobný princip, kdy se nastavuje firewall způsobem, který umožňuje komunikaci pouze směrem z počítače čí sítě ven. }. Tuto komunikaci zajištujě pomocí známých principů \textit{reverse proxy} a \textit{load balancingu}.

%Mohlo by se zdát, že \textit{ingress} je duplicitním řešením pro již existující objekt \textit{Service} v reřimu \textit{NodePort} nebo \textit{LoadBalancer}. Není tomu tak, objekt \textit{ingress} doplňuje a rozšiřuje některé funkce \textit{Serrvice} a zároveň některé z problémů, které mohou při použití \textit{Service} nastat.




